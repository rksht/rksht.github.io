<!DOCTYPE html>
<html><head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Temp Notes - This</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta property="og:title" content="Temp Notes" />
<meta property="og:description" content="The &ldquo;GradGlobalWrtParams&rdquo; operator The global function is $G$ and the node is $f$. We also denote the successors of $f$ as $succ(f)$.
Each such node as a list of parameters it depends on. The concatenated list of all parameters of all nodes form the parameters of $G$. Assume that gradient for $G$ is computable everywhere.
So, we have the gradient of $G$ like
$$ \nabla G = \langle \frac{\partial G}{\partial w_1}, \frac{\partial G}{\partial w_2}, \ldots \frac{\partial G}{\partial w_n} \rangle $$" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://rksht.github.io/posts/temp_notes/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-05-15T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2020-05-15T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Temp Notes"/>
<meta name="twitter:description" content="The &ldquo;GradGlobalWrtParams&rdquo; operator The global function is $G$ and the node is $f$. We also denote the successors of $f$ as $succ(f)$.
Each such node as a list of parameters it depends on. The concatenated list of all parameters of all nodes form the parameters of $G$. Assume that gradient for $G$ is computable everywhere.
So, we have the gradient of $G$ like
$$ \nabla G = \langle \frac{\partial G}{\partial w_1}, \frac{\partial G}{\partial w_2}, \ldots \frac{\partial G}{\partial w_n} \rangle $$"/>

	<link href="https://fonts.googleapis.com/css2?family=Fira+Sans&display=swap" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet">
	<link rel="stylesheet" type="text/css" media="screen" href="https://rksht.github.io/css/main.css" />

	<script
  type="text/javascript"
  async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

</head><body>
        <div class="content"><header>
	<div class="main">
		<a href="https://rksht.github.io">This</a>
	</div>
	<nav>
		
	</nav>
</header>

<main>
	<article>
		<div class="title">
			<h1 class="title">Temp Notes</h1>
			<div class="meta">Posted on May 15, 2020</div>
		</div>
		

		<section class="body">
			<h2 id="the-gradglobalwrtparams-operator">The &ldquo;GradGlobalWrtParams&rdquo; operator</h2>
<p>The global function is $G$ and the node is $f$. We also denote the successors of $f$ as $succ(f)$.</p>
<p>Each such node as a list of parameters it depends on. The concatenated list of all parameters of all nodes form the parameters of $G$. Assume that gradient for $G$ is computable everywhere.</p>
<p>So, we have the gradient of $G$ like</p>
<p>$$
\nabla G = 	\langle
\frac{\partial G}{\partial w_1},
\frac{\partial G}{\partial w_2}, \ldots
\frac{\partial G}{\partial w_n}
\rangle
$$</p>
<p>We can definitely assign the parameter list of each node $f$ as a sub-array of $\nabla G$. If $\vec{w_f}$ denotes the parameter list of $f$, such that it corresponds to the terms in range $[i \ldots j]$ of the global paramter list (should be that $0 \lt (j - i) \lt n$), the gradient descent update <em>at</em> $f$&rsquo;s params is</p>
<p>$$
\vec{w_f} \leftarrow (\vec{w_f} - \nabla G[i \ldots j])
$$</p>
<p>So doing gradient descent is simply updating the parameter list of each node by subtracing the corresponding sublist of $\nabla G$.</p>
<p>An idempotent mapping f: S -&gt; S ∪ {⊥} consists of ordered tuples such that</p>
<ul>
<li>
<p>∀x ∈ S, ∃y ∈ S ∪ {⊥}, (x, y) ∈ f</p>
</li>
<li>
<p>(x, y) ∈ f ⟹ ∄(p, _) ∈ f where p = x</p>
</li>
<li>
<p>(x, y) ∈ f ⟹ (y, y) ∈ f</p>
</li>
</ul>
<p>How many idempotent mappings can be created for a given set S?</p>
<p>See wikipedia</p>
<p>Something to note. There will always be some elements that can&rsquo;t be mapped to
another element in S. For these we introduce the symbol ⊥ and map them to
this, keep f a total function.</p>
<hr>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-hs" data-lang="hs"><span style="color:#f92672">#!/</span>usr<span style="color:#f92672">/</span>bin<span style="color:#f92672">/</span>env stack
<span style="color:#75715e">{- stack runghc --resolver lts-14.20
</span><span style="color:#75715e">-}</span>

<span style="color:#75715e">{-# LANGUAGE TupleSections #-}</span>

<span style="color:#66d9ef">module</span> Main
<span style="color:#66d9ef">where</span>

<span style="color:#66d9ef">import</span>            Data.Foldable                  ( <span style="color:#a6e22e">foldl</span> )
<span style="color:#66d9ef">import</span>            Data.Functor                   ( <span style="color:#a6e22e">fmap</span>  )

<span style="color:#66d9ef">type</span> <span style="color:#66d9ef">Partition</span> a <span style="color:#f92672">=</span> ([a], [a])

<span style="color:#75715e">-- Given a list of elements, returns all possible *ordered* 2-partitions of</span>
<span style="color:#75715e">-- these elements.</span>
<span style="color:#a6e22e">generatePartitions</span> <span style="color:#f92672">::</span> [a] <span style="color:#f92672">-&gt;</span> [<span style="color:#66d9ef">Partition</span> a]

<span style="color:#a6e22e">generatePartitions</span> (x <span style="color:#66d9ef">:</span> xs) <span style="color:#f92672">=</span> foldl
  (<span style="color:#a6e22e">\</span>accPartitions (left, right) <span style="color:#f92672">-&gt;</span>
    ((x <span style="color:#66d9ef">:</span> left), right) <span style="color:#66d9ef">:</span> ((left, (x <span style="color:#66d9ef">:</span> right)) <span style="color:#66d9ef">:</span> accPartitions)
  )
  <span style="color:#66d9ef">[]</span>
  (generatePartitions xs)

<span style="color:#a6e22e">generatePartitions</span> <span style="color:#66d9ef">[]</span> <span style="color:#f92672">=</span> [(<span style="color:#66d9ef">[]</span>, <span style="color:#66d9ef">[]</span>)]

<span style="color:#75715e">-- A single mapping is a set of ordered tuples. We must make sure that it is</span>
<span style="color:#75715e">-- indeed a mapping (many-to-one) ourselves. We don&#39;t use a set explicitly but</span>
<span style="color:#75715e">-- keep the tuples in list.</span>
<span style="color:#66d9ef">type</span> <span style="color:#66d9ef">Mapping</span> a b <span style="color:#f92672">=</span> [(a, b)]

<span style="color:#a6e22e">generateAllMappings</span> <span style="color:#f92672">::</span> [a] <span style="color:#f92672">-&gt;</span> [b] <span style="color:#f92672">-&gt;</span> [<span style="color:#66d9ef">Mapping</span> a b]

<span style="color:#a6e22e">generateAllMappings</span> <span style="color:#66d9ef">[]</span> <span style="color:#66d9ef">_</span> <span style="color:#f92672">=</span> [<span style="color:#66d9ef">[]</span>]

<span style="color:#a6e22e">generateAllMappings</span> (x<span style="color:#66d9ef">:</span>xs) ys <span style="color:#f92672">=</span> <span style="color:#66d9ef">do</span>
  xy <span style="color:#f92672">&lt;-</span> ((x,) <span style="color:#f92672">&lt;$&gt;</span> ys)
  (xy <span style="color:#66d9ef">:</span>) <span style="color:#f92672">&lt;$&gt;</span> (generateAllMappings xs ys)


<span style="color:#a6e22e">generateIdempotentMappings</span> <span style="color:#f92672">::</span> ([a], [a]) <span style="color:#f92672">-&gt;</span> [<span style="color:#66d9ef">Mapping</span> a a]
<span style="color:#a6e22e">generateIdempotentMappings</span> (fixedPoints, nonFixedPoints) <span style="color:#f92672">=</span>
  <span style="color:#66d9ef">let</span> identityMappedElems <span style="color:#f92672">=</span> fmap (<span style="color:#a6e22e">\</span>x <span style="color:#f92672">-&gt;</span> (x, x)) fixedPoints <span style="color:#66d9ef">in</span>
  <span style="color:#66d9ef">let</span> nonIdentityMappedElems <span style="color:#f92672">=</span> generateAllMappings nonFixedPoints fixedPoints <span style="color:#66d9ef">in</span>
    fmap (identityMappedElems <span style="color:#f92672">++</span>) nonIdentityMappedElems


<span style="color:#a6e22e">generateIdempotentMappingsFromElements</span> <span style="color:#f92672">::</span> [a] <span style="color:#f92672">-&gt;</span> [<span style="color:#66d9ef">Mapping</span> a a]
<span style="color:#a6e22e">generateIdempotentMappingsFromElements</span> elements <span style="color:#f92672">=</span>
  foldl (<span style="color:#f92672">++</span>) <span style="color:#66d9ef">[]</span> (generateIdempotentMappings <span style="color:#f92672">&lt;$&gt;</span> (generatePartitions elements))

<span style="color:#a6e22e">main</span> <span style="color:#f92672">=</span> putStrLn <span style="color:#f92672">$</span> show <span style="color:#f92672">$</span> length <span style="color:#f92672">$</span> generateIdempotentMappingsFromElements [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>]
</code></pre></div><p>Better understanding of <code>join</code> is needed - <code>generatePartitions</code> is a good monad to ponder with.</p>
<h2 id="lagrange-multipliers">Lagrange multipliers</h2>
<p>The main theorem the technique is based on is as follows -</p>
<p>If the level set $f(\vec{x}) = c$ is totally differentiable for all values of
$\vec{x}$ that lie on the (i.e. subject to) the constraint level set
$g(\vec{x}) = 0$, the critical points of $f$ are exactly those points where
$\vec{\nabla} f = \lambda \vec{\nabla} g$.</p>
<h2 id="affine-and-convex-set">Affine and Convex set</h2>
<p>Affine sets, the weights are not constrained to be positive only, can be
negative also. Convex sets they must be positive which means the weights must be
in range [0 .. 1].</p>
<p>Ellipsoid aka &ldquo;Stretched sphere&rdquo;</p>
<p>A symmetric matrix has orthogonal eigenbasis.</p>
<p>A positive definitive matrix is one with positive eigenvalues</p>
<p>Any scaling linear transform that stretches or squeezes (but doesn&rsquo;t reverse) about some orthogonal
basis will have these basis vectors as the eigenbasis.</p>
<p>The inverse of this matrix will make the ellipse a circle.</p>
<p>So the ellipse at origin major axis of length 1 will have all points x inside it
satisfy</p>
<p>inv(S) x</p>
<h2 id="eigenvalue-facts">Eigenvalue facts</h2>
<ul>
<li>
<p>A square matrix $A$ with dim $n$, has a multiset of eigenvalues $\text{Eigenvalues}$ such that $|\text{Eigenvalues}| =
n$</p>
</li>
<li>
<p>$1 \le |\text{Unique}(\text{Eigenvalues})| \le n$</p>
</li>
<li>
<p>For any $v \in \text{Unique}(\text{Eigenvalues})$, $\text{dim }S(v) \le \text{mul}(v)$</p>
</li>
<li>
<p>Sum of dim of each eigenspace $\le$ $n$</p>
</li>
<li>
<p>Each unique eigenvalue has a one to one correspondance with a subspace of
$R^n$, called the eigenspace of that eigenvalue.</p>
</li>
<li>
<p>Eigenbasis exists $\Leftrightarrow$ dim of eigenspace of each eigenvalue $=$
occurences of that eigenvalue in $\text{Eigenvalues}$</p>
</li>
<li>
<p>Number of unique eigenvalues = $n$ $\Rightarrow$ Eigenbasis exists</p>
<p>Also implies each eigenspace has dim of 1</p>
</li>
<li>
<p>Taking bases from each eigenspace and concatenating into a single list of
vectors gives you a basis of $R^n$ called the eigenbasis for $A$, since
vectors from different eigenspaces are linearly indepedent.</p>
</li>
</ul>
<pre><code>20:27:07     snyp | Matrix has eigenbasis &lt;=&gt; Matrix has n eigenvalues (including repeats according to algebraic multiplicity) ?         │ ^[_
2.  ##c++        │20:28:09     snyp | Can it be that even with repeats as per  multiplicty the dimension of an eigenspace might be less than multiplicity? │ _explodes
3.  ##C++-general│20:33:57 Z-module | no, it has an eigenbasis iff for each particular eigenvalue c, if that c has algebraic multiplicity k, then its      │ _kmh_
4.  ##OpenGL     │                  | eigenspace has dimension k (that is, k linearly independent eigenvectors for that c exist).                          │ _tjr_
5.  ##javascript │20:36:21 Z-module | For example matrix [1,1; 0,1]  has only the single eigenvalue 1, of alg. mult. 2, but its eigenspace is just { (r,0) │ _W_
6.  #go-nuts     │                  | : r in the field }  which is only 1-dimensional. There is no eigenbasis here.                                        │ _Warl0ck
7.  ##math       │20:37:09 Z-module | For each eigenvalue c, the geometric multiplicity can be any of 1, ..., k  where k is c's algebraic multiplicity.    │ a3Dman_
                 │20:38:55     snyp | Z-module: oh i see, the dimension of each particular eigenspace should be equal to the multiplicity of that          │ abdulocracy
                 │                  | eigenvalue.                                                                                                          │ abhi1802
                 │20:39:13     snyp | algebraic multiplicity                                                                                               │ adadelta
                 │20:39:19 Z-module | So if the n eigenvalues are all distinct, that forces each one to have alg. mult. = geom. mult. = 1, so here there   │ Adluc
                 │                  | will have to be an eigenbasis.                                                                                       │ affinespaces
                 │20:39:37 Z-module | right, on what you just said                                                                                         │ aib
                 │20:39:56     snyp | n distinct eigenvalues =&gt; eigenbasis exists                                                                          │ AimHere
                 │20:40:05 Z-module | yes                                                                                                                  │ albel727
                 │20:40:09     snyp | ah                                                                                                                   │ Alchemical
                 │20:40:11     snyp | thanks                                                                                                               │ aleph-
                 │20:41:25 Z-module | a bit more strongly, any time you have a set S of particular eigenvectors where each one belongs to a different      │ AlexAltea
                 │                  | eigenvalue, then S is linearly independent. You can prove that quite directly.                                       │ alexknvl
                 │20:42:23 Z-module | so if |S| = n, with each vector belonging to a different eigenvalue (so the full n distinct eigenvalues exist here), │ ali1234
                 │                  | then S is a basis. So it's an eigenbasis.                                                                            │ Alina-malina
                 │20:43:41 Z-module | but if even a *single* eigenvalue c has geometric mult. &lt; its algebraic mult., then no eigenbasis can exist.         │ alip
                 │20:44:21 Z-module | Once you really learn and understand the Jordan form of a matrix, all this info can be read off from it directly.    │ alkyl
                 │20:44:37 Z-module | (an eigenbasis exists iff the Jordan form is diagonal)                                                               │ aloril
                 │20:54:30     snyp | Z-module: that single eigenvalue having &lt; algebraic mult. can be proven from the fact that some of algebraic mult =  │ Alpha3031[m]
                 │                  | n, right?                                                                                                            │ alphamule
                 │20:54:34     snyp | s/some/sum                                                                                                           │ AlpineLlama
                 │20:55:24 Z-module | yes                                                                                                                  │ Amaan
                 │20:55:29 Z-module | (you mean sum of)                                                                                                    │ amalek
                 │20:59:59 Z-module | So to summarize:  If the matrix is n x n, and if c_1,..., c_k  are all the distinct eigenvalues, and if &quot;AM&quot;, &quot;GM&quot;   │ amosbird
                 │                  | stand for algebraic / geometric multiplicity, then: for each j from 1 to k,  1 &lt;= GM(c_j) &lt;= AM(c_j),  and  \sum_j   │ amuro
                 │                  | AM(c_j) = n,  and  \sum_j GM(c_j) = the dimension of the largest possible independent set of eigenvectors -- this    │ andytoshi
                 │                  | will always be &gt;= k  and  &lt;= n.  It = n iff the matrix is diagonalizable (an eigenbasis exists).                     │ AngryOwl      
                 │21:01:08 Z-module | (wow, &quot;diagonalizable&quot; is a mouthful as a word -- 7 syllables)                                                       │ angular_mike
                 │21:02:27     snyp | Z-module: yeah.. was writing a similar summary myself in my notes, haha 

</code></pre><p>Think of it like this - when you diagonalize a matrix, $E D E^{-1}$, the scalars in $D$ can be non-unique. Hence, dimension of the space of a unique eigenvalue can be greater than one. But of course it can be the case that you cannot diagonalize a given matrix since the dimension of an eigenspace is less than the algebraic mult.</p>
<p>Eigenspaces are the main component. $A x = c x$ where $x$ is an eigenvector and c is the eigenvalue of A.</p>
<h2 id="symmetric-real-matrices-non-zero">Symmetric real matrices (non-zero)</h2>
<ul>
<li>Real symmetric matrices have at least one real eigenvalue.</li>
<li>Dimension of each eigenspace of real symmetric matrices  =
Eigenvalue&rsquo;s algebraic mult</li>
</ul>
<h2 id="detour-into-orthonormal-bases">Detour into orthonormal bases</h2>
<p>Turns out that only if your basis vectors are mutually orthogonal (and normalized of course), the coefficients of a vector wrt this basis are the dot products (projection) of vector with each basis vector.</p>
<p>If they aren&rsquo;t orthonormal, it&rsquo;s not true. You can&rsquo;t dot product a given vector with each of the basis vectors and use the resulting scalars as coefficients in the linear combination of these non orthonormal basis vectors.</p>
<p>Take the non-orthonormal basis vectors $b_1 = \langle 1, 1 \rangle$ and $b_2 = \langle 1, 0 \rangle$ in $R^2$. The vector $\langle 1, 2 \rangle$ wrt the standard basis has the following coefficients wrt this basis - $c_1 = 3$ and $c_2 = 1$. Now the linear combination of these scalars with the basis vectors is $c_1 b_1 + c_2 b_2 = [3, 3] + [1, 0] = [4, 3] \neq [1, 2]$</p>
<h2 id="coordinate-system">Coordinate system</h2>
<p>A system of assigining unique tuples to each vector. When using an orthonormal linear basis, it&rsquo;s as simple as taking the inner product with each basis vector and then creating a tuple from the resulting scalars.</p>
<p>A spherical coordinate system is different. To illustrate, let us instead look at a scenario that is not quite spherical coordinates but gives a very good idea of what we are trying to formalize.</p>
<p>Suppose that you are on a spaceship. At any instant of time you can create a basis for R^3 using the following basis vectors</p>
<ul>
<li>&ldquo;FromEarth&rdquo; - Which is the Position(t) - EarthPosition</li>
<li>Two more orthonormal vectors that are orthogonal to FromEarth (use the Eberly method - project FromEarth to either xy, yz, or zx plane and orthogonalize)</li>
</ul>
<p>So you can see that the basis vectors are definitely not constant wrt time.  FromEarth is a function of position, which is a function of time.</p>
<p>So the basis $B(\text{Position}) = A$ is list of vectors (or a matrix) that depends on position of spaceship.</p>
<p>Now, let&rsquo;s look at spherical coordinates.</p>
<p>A vector, or more specifically a position vector is represented by the tuple $(r, \theta, \pi)$</p>
<p>Clearly, if we are at a certain point, we can create an orthonormal basis that depends on the point&rsquo;s spherical coordinates.</p>
<p>Just like the FromEarth vector, we can denote the vector $\text{normalize}(P - O) = \hat{r}$, where $O$ is the origin in our spherical coordinate system. TODO: not quite. Why use $dr/|dr|$ then?</p>
<p>What about two other vectors that we need for the basis?</p>
<h2 id="basis-transformation-forward-and-backward">Basis transformation (&ldquo;Forward&rdquo; and &ldquo;Backward&rdquo;)</h2>
<h3 id="change-of-basis">Change of basis</h3>
<p>The <a href="http://physastro-msci.tripod.com/webonmediacontents/notes1.pdf">lecture notes</a> are good, but some terminology needs to be cleared.</p>
<p>The change of basis matrix from a basis U to basis E is a matrix that, when multiplied to a vector tuple represented wrt basis U, results in a vector tuple wrt basis E.</p>
<p>These <a href="https://www.youtube.com/playlist?list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG">youtube lectures</a> are also pretty nice.</p>
<p>So, let&rsquo;s say that the $i$-th old basis vector $\vec u_1 = a_1 \vec e_1 + a_2 \vec e_2 + a_3 \vec e_3$. Let&rsquo;s just express this as a matrix multiplication.</p>
<p>$$
\vec u_1 =
\begin{bmatrix}
a_1 &amp; a_2 &amp; a_3
\end{bmatrix}</p>
<p>\begin{bmatrix}
\vec e_1 \<br>
\vec e_2 \<br>
\vec e_3
\end{bmatrix}
$$</p>
<p>We are looking at only the coefficients of the $u_1$ basis vector. If we do solve for the matrix $A$ in the equation $U = AE$ the <strong>row</strong> $i$ of $A$ will be the coefficient of $\vec u_i$ wrt the $E$ basis. So $A^\intercal$ is the change of basis matrix from $U$ to $E$.</p>
<p>That&rsquo;s the transpose of $A$ not the inverse. And sure the lecture video and the tensor book talk about the transform for the basis vectors $\vec u_i$ themselves is the inverse of $A$. Except for me, this &ldquo;opposite&rdquo;
approach is better. I like to view change of basis as a transform that is supposed to be applied on general vectors expressed wrt some basis to get components wrt some other basis - not the transform that maps the basis vectors to the other basis. But these two are related, in particular they are inverses of each other.</p>
<p>Think of it like this - You are mapping basis to basis. In this situation the map is $L(\vec u_i) = \vec e_i$. The matrix $C = A^\intercal$ is the change of basis matrix from $U$ to $E$. But the matrix of $L$ wrt the input basis $U$ and output basis $U$ (yes, same) is $C^{-1}$. Try with the matrix column approach (in Axler).</p>
<h2 id="covectors-incomplete-understanding">Covectors (Incomplete understanding)</h2>
<p>Are covectors just distance functions to planes passing through origin?</p>
<p>The a distance function $D_n \equiv D_n(\vec x)= \vec n \cdot \vec x$ where $\vec n$ is the normal</p>
<ul>
<li>
<p>Obeys the scaling property
$$
k D_n =  k \vec n \cdot \vec x = D_{k\vec n}
$$</p>
</li>
<li>
<p>And the additive property
$$
D_{n_1}(\vec x) + D_{n_2}(\vec x) = \vec n_1 \cdot \vec x + \vec n_2 \cdot \vec x = (\vec n_1 + \vec n_2) \cdot \vec x = D_{n_1 + n_2}(\vec x)
$$</p>
</li>
</ul>
<p>Then what else does covectors bring?</p>
<p>The first insight is that the set of functions ${D_n | \forall \vec n \in \Reals ^3}$ is a vector space.</p>
<h1 id="covector-bases">Covector Bases</h1>
<p>You can have basis functions that construct other functions by linear
combinations. Like the sinusoids in Fourier transform, or the XYZ response
functions in the CIE color spaces, or Bezier curve basis functions.</p>
<p>So why not have basis functions for covectors? Indeed we can. Let&rsquo;s think about
it for a little. Suppose that the underlying vector space is 2D. So the covector
space has functions of the form $C(x, y) = ax + by$.</p>
<p>For a moment, we work in the standard basis. Since the function C is
completely fixed by the choice of a and b, we create 2 functions $C_1$ and $C_2$,
with $(a, b) = (1, 0)$ and $(a, b) = (0, 1)$ respectively.</p>
<p>So $C_1(1, 0) = 1$, $C_1(0, 1) = 0$. And $C_2(1, 0) = 0$, and $C_2(0, 1) = 1$.</p>
<p>Any covector $C$ can be written as a linear combination of $C_1$ and $C_2$.</p>
<p>$$
C(x, y) = a * C_1(x, y) + b * C_2(x, y)
$$</p>
<p>This seems rather convoluted way to write $C$, but the idea is that $C_1$ and $C_2$
should not depend on the choice of basis. Of course, during actual computation
with numbers, the input components to C, i.e. x and y should be wrt the basis
that C_1 and C_2 are built from.</p>
<p>So, what should the the functions C_1 and C_2 be? Let&rsquo;s first fix a basis for
the underlying vector space - B_1 and B_2.</p>
<p>$$
C_1(B_1) = 1.0
$$
$$
C_1(B_2) = 0.0
$$
$$
C_2(B_1) = 1.0
$$
$$
C_2(B_2) = 0.0
$$</p>
<p>Let&rsquo;s call the vector [a, b] (wrt the basis we fix) the &ldquo;scaled normal&rdquo; of C_1.
It&rsquo;s actually isomorphic, since C is fixed by [a, b].</p>
<p>The scaled normals are super simple to calculate if the underlying basis is
orthogonal. C_1&rsquo;s scaled normal is just B_1 / ||B_1||</p>
<p>Same for C_2, the scaled normal is B_2 / ||B_2||</p>
<p>But it is not as trivial if the underlying basis vectors are not orthogonal to each other.</p>
<p>Let the scaled normal associated with $C_i$ be $S_i$. Then as per the above conditions it should be such that</p>
<p>$$
\vec S_i \cdot \vec B_i =
\begin{cases}
1, &amp; \text{if}\ i = j \<br>
0, &amp; \text{if}\ i \neq j
\end{cases}
$$</p>
<p>How to calculate such normals? Do they even exist for any arbitrary non-orthogonal basis?</p>
<p>If $\vec B_i$&rsquo;s are the original basis vectors, we may be able to calculate a dual basis $\vec D_i$. In the case of a finite dimensional vector space, the dual basis always exist. A vector $\vec x$ will have its components $x_i = \vec x \cdot \vec D_i$</p>
<p>$V =$ the vector space</p>
<p>$V'= {f \mid f \in \text{Linear}\ \text{and}\ f : V \rightarrow \Reals} =$ the dual vector space</p>
<hr>
<ul>
<li>Study about autograd</li>
<li>CNN</li>
<li>First read the impl booK</li>
</ul>
<p><a href="https://jeremykun.com/2012/12/09/neural-networks-and-backpropagation/">https://jeremykun.com/2012/12/09/neural-networks-and-backpropagation/</a>
&ndash; Tinker with pytorch tensors and derivatives using autograd for this simple use case - derivative of a logit? Eh.. maybe sometime later.</p>
<h2 id="dense">Dense</h2>
<p>There is no fixed way to determine the number of nodes in any hidden layer.</p>
<h2 id="cnn">CNN</h2>
<p>Will see how requires_grad and autograd works by implementing a CNN.</p>
<p>Need some images first. Lots of them. Torchvision has those bro, nvm.</p>
<p>Convolution layer -&gt; Apply on image -&gt; &ldquo;Feature map&rdquo; (feature vector?)</p>
<p>Better to use Tensorflow? Conda has rocm package. Down the line. Not now.</p>
<p>Tweak off with pytorch bro.</p>
<h2 id="probability-independence-concepts">Probability Independence concepts</h2>
<p>Mutual indepence -&gt; P(A and B and C) = P(A) . P(B) . P(C)</p>
<p>Any event A is independent of <em>any</em> intersection of other events. This is a much
stricter constraint than pairwise independence.</p>
<p>Mutual independence =&gt; Pairwise independence</p>
<h2 id="bayesian-networks">Bayesian Networks</h2>
<p>Concise way to represent joint distribution. Takes advantage of independent
random variables.</p>
<p>The idea is actually similar but not the same from the conditional probability
trees we drew in school.</p>
<p>We construct a DAG where each vertex represents a random variable. Random
variable, not value. Say we have a vertex for the boolean random variable A. In
school we would have two vertices A and ~A denoting that A = true and A = false
respectively. But in a Bayesian network, we only have vertices representing the
variable itself, not the value it assumes. The probabilities of it being true or
false (or any other value if it&rsquo;s not boolean) is stored in a conditional
probability table corresponding to that very vertex.</p>
<p>But conditional indepedence is encoded in a particular way in a Bayesian
network.</p>
<p>Conditional indepedence, not pure independence.</p>
<h2 id="detour-into-the-concept-of-factor">Detour into the concept of Factor</h2>
<p>Like tables in SQL. Just multivariable functions. Except the arguments values of
random variables.</p>
<p>Factor product is similar to natural join with the value of the function in the
two tables multiplied.</p>
<p>Factor marginalization is like group by over a set of argument random variables,
with the corresponding values of the function added up. The variables that are
not in the group by set are simply not noted in the new table. When working with
joint probability distribution tables, these summed values are called marginal
probability. So yeah. We are generalizing these concepts somewhat.</p>
<h2 id="intercausal-reasoning">Intercausal reasoning</h2>
<p>Kind of like bayesian inference? P(cause | effect)?</p>
<p>Just like conditional independence, conditional dependence is a possibility. If
two causes are indepedent as prior, knowing an effect value can make the two
causes dependent. Like P(cause1 | cause2 . effect) != P(cause1), but without any
conditioning on the effect we do have P(cause1 | cause2) = P(cause1).
Simple example - Knowing the output of an OR function induces a dependency on
the inputs.</p>
<h2 id="naive-bayes-model">Naive Bayes model</h2>
<p>Instead of an intricate Bayesian network, a simple model is to have a network
with a single layer. Rings a bell? Like a linear regression model in the case of
neural networks? The root vertex stands for a random variable taking values c1,
&hellip;, c_n denoting a class. All events are mutually independent conditioned on C.</p>
<p>So <code>P(C, X1, X2, ..., Xn) = P(C) . Product{i = 1 to n} P(X_i | C)</code>. This is the
factorization of the joint probability.</p>
<p>But if we want to go the inference direction, i.e. P(cause | effects), we have</p>
<pre><code>P(C = c1 | x1, ..., xn) = P(c1, x1, ..., x_n) / P(x1, ..., x_n)
                        = P(c1) . Product{i = 1 to n} P(x_i | c1) / P(x1, ..., xn)
                        = P(c1) . Product{i = 1 to n} P(x_i | c1) * some_constant
</code></pre><p>So we can compare <code>P(C = c1 | x1 ... x_n)</code> and <code>P(C = c2 | x1 ... x_n)</code> without
dividing by the <code>some_constant (= P(x1, ..., x_n))</code></p>
<p><em>How to train a Naive Bayes model and use it?</em></p>
<h2 id="flow-of-influence-in-a-bayes-network">Flow of influence in a Bayes Network</h2>
<p>So yeah, there is no local property that lets us tell that two random variables
are independent. In fact d-separation is a rather global algorithm requiring
modifying the whole graph before answering questions about independence of
events.</p>
<p>Simple note on d-separation
<a href="http://web.mit.edu/jmn/www/6.034/d-separation.pdf">http://web.mit.edu/jmn/www/6.034/d-separation.pdf</a></p>
<p>Pausing discussion on this.</p>
<h2 id="interval-arithmetic">Interval arithmetic</h2>
<p>RobustGeometric book has chapter on this. Want to read sometime.</p>
<h2 id="standard-to-general-normal-deviate">Standard to General Normal Deviate</h2>
<p>The standard normal distribution is defined as</p>
<pre><code>S(x) = some_expression_of(x)
</code></pre>
<p>Any other normal distribution is obtained by shifting-then-scaling the graph of S, and that means something like</p>
<pre><code>F(x) = S((x - μ)/σ)
</code></pre>
<p>Now, I give you a universe U = {items}</p>
<p>And I obtain a sample from that universe, D = [&hellip;items&hellip;]. A sample is not a set, but a list (even unordered set is apt).</p>
<p>I tell you that items in the sample are distributed according to the standard normal distribution.</p>
<p>It means that if</p>
<pre><code>item ∈ D ⟹ frequency(item) / count(D) ≈ S(item)
</code></pre>
<p>So don&rsquo;t confuse D as being a discretized S. It definitely is not.</p>
<p>Usually in this setting we enumerate the items so item is an integer.</p>
<p>Intuitively we realize that we can map items (unique ones) into another list D'</p>
<pre><code>item ∈ D
⟹  mapped(item) ∈ D' and frequency(mapped(item)) / count(D') ≈ F(item)

where F(item) is a different normal distrbution
</code></pre>
<p>If we know the μ and σ of F we can prove that</p>
<pre><code>mapped(item) = σ item + μ
</code></pre>
<h2 id="mean-over-samples-and-clt">Mean over samples and CLT</h2>
<p>We have multiple random variables $X_i$ that follow the same distribution. We can have a tuple of these $(X_1, X_2, &hellip;, X_N)$.</p>
<p>Note that even if the random variables are drawn from the same distribution, they are not the <em>same</em> mathematical variables. That&rsquo;s one of the reasons why we say these are <em>independently distributed</em> random variables. In programming language terms we may say these are different instances of the random variable which is a function. The $(&hellip;, X_i, &hellip;)$ vector is a function, just like each random variable $X_i$ is a function. What is same among these &ldquo;variables&rdquo; are their probabilistic properties - they have the same mean, variance, median, etc.</p>
<p>Let&rsquo;s create a derived random variable which is just the sum of these iid random variables: $\bar{X}<em>n = \sum</em>{i=1}^n X_i$.</p>
<p>Then $\bar{X}$ has a mean of $n\mu$ (as per linearity of expectation) and variance of $n\sigma^2$ (as per linearity of variance of independent variables).</p>
<p>What should be the sample size? We need more info.</p>
<p>We want our sample mean, which is the &ldquo;estimate&rdquo; for $p$ the population mean to be within a distance of d from the fraction p with a probability of c.</p>
<p>That&rsquo;s what MCS book is doing and using Chebyshev&rsquo;s inequality to assert a mininum bound on n in order to ensure that probability. In the voter problem, the way MCS phrases the samples is like so</p>
<ul>
<li>Number of samples = $n$</li>
<li>Sample size = $1$</li>
<li>Sample item distribution = Bernoulli</li>
<li>$S_n = \sum_{i=1}^n X_i$ has a _binomial distrbution_ and $S_n/n$ is the estimate for $p$, the population mean.</li>
</ul>
<p>In the gumball scenario (1), HFS has samples like</p>
<ul>
<li>Number of samples = $1$</li>
<li>Sample size = $n$</li>
<li>Sample item distribution = Binomial</li>
<li>No interesting sum since we just have $1$ sample</li>
</ul>
<p>Clearly we can frame our problem in multiple ways as we see in these two phrasings. What&rsquo;s the &ldquo;general&rdquo; framework?</p>
<p>The idea is to obtain good confidence bounds on the &ldquo;mean over samples $S_n/n$&rdquo; using Chebyshev&rsquo;s inequality. (Read from MCS and other text) Just writing the formula for reference.</p>
<p>$$ Pr\left[\left(\frac{S_n}{n} - \mu\right) \geq x\right] \leq \frac{1}{n}\left(\frac{\sigma}{x}\right)^2 $$</p>
<p>As $n \rightarrow \infty$, $\frac{S_n}{n}$ converges <em>in probability</em> to $\mu$.  That is the LLN. Contrary to some other writeups, we <em>can</em> make some deductions about the distribution of the random variable $S_n/n$. As $n \rightarrow \infty$, the variance of $S_n/n$ tends to become $0$, which means for a large enough $n$ (number of samples), the distribution is actually concentrated about at a single value on the X axis. This value is close to $\mu$. That&rsquo;s it. And that&rsquo;s pretty powerful information.</p>
<p>With a little bit of tweaking, we can map the variates $S_n$ to the standard normal variate. The mapping is $Z = \frac{S_n - n\mu}{\sqrt{n}\sigma}$ and if we fix every parameter except let $n \rightarrow \infty$, $P(Z &lt; z) \rightarrow P(Z_n &lt; z)$. This means that the PDF of $Z$ converges to the standard normal pdf. Function converging to another function, criticool.</p>
<p>That&rsquo;s surprising because <strong>we don&rsquo;t have <em>any</em> info about the distribution of the samples themselves and not a whole lot about $S_n$ either.</strong> So as long as the sample distributions are iid(well actually just same mean and variance would do), we can map the sample mean random variable to the standard normal random variable. All of this happens in  <em>approximation</em> btw - albeit a really good approximation and the mapped random variable converges to the standard normal variable <em>in probability</em>.</p>
<p>Concepts</p>
<ul>
<li>Chebyshev&rsquo;s inequality</li>
<li>Estimation by random sampling</li>
<li>Pairwise independent sampling</li>
<li>Weak law of large numbers</li>
<li>Significance of p values(?)</li>
<li>Chernoff Bound(?)</li>
<li>Normal approximation to binomials</li>
<li>Confidence Interval</li>
</ul>
<h4 id="geometric-distribution-is-memoryless">Geometric distribution is memoryless</h4>
<p>The identity that holds is
$$
P\left[ X &gt; a + b \mid X &gt; a \right] = P\left[X &gt;
b\right]
$$</p>
<p>But does this not hold - $P\left[ X = a + b \mid X &gt; a \right] = P\left[X =
b\right]$ ? Yes. Could give a simple derivation as proof, but better to
understand intuitively first.</p>
<p>It&rsquo;s important to remember what the random variable $X$ represents and thus $X &gt;
a$ means. $X$ is the count of trials before stopping. So $X &gt; a$ means we didn&rsquo;t
stop at the $a$-th trial. So what is the probability that we got success at the
$(a + b)$-th trial? Since all trials are indepedent, it&rsquo;s the same probability
we have if we started fresh and got success at the $b$-th trial. I was thinking
in an incorrect way before, considering events when $X = a + 1$, or $X = a + 2$,
and so on. This doesn&rsquo;t make sense, because then $X &gt; a + b$ would be $0$ since
we got $X = n$ means we stop at $n$-th trial.</p>
<h2 id="classical-statistics">Classical Statistics</h2>
<p>Any property, for convenience, a scalar property of the population is considered
to be an unknown constant, not a random variable.</p>
<p>Call the scalar property $\theta$, and we do the usual sampling, $N$ times such
that the mean over the samples is</p>
<p>$$
\hat{\theta} = \frac{\sum_{i = 1}^N X_i}{N}
$$</p>
<p>The CLT says that for large enough $N$, then the sample mean $\hat{\theta}
\xrightarrow[]{\text{i.p}} \theta$.</p>
<p>An identity: $E\left[Z^2\right] = \text{var}(Z) + (E\left[Z\right])^2$.</p>
<p>We can use this to get the expecation of the mean square difference of the sample which is defined as $(\hat{\theta} - \theta)^2$</p>
<p>Confidence interval for the sample mean is pretty simple to establish with the normal distribution approximation (CLT) to obtain a lower and upper bound, i.e.  an interval on the values of the estimate such that these values occur with a certain probability at least.</p>
<p>Another important primitive is the inverse CDF for the standard normal distribution. $\text{Inverse}(\text{total_probability}) = x$ where $\Pr(X &lt; x)
= \text{total_probability}$. Since the normal distribution is symmetric and monotonic in either side of the mean x coordinate, the inverse CDF can be used to calculate the upper and lower bounds on x coordinate for a given total probability easily.</p>
<h2 id="hypothesis-testing">Hypothesis testing</h2>
<p>Think it is better to just construct a proper logical proposition first. This proposition is called the hypothesis. The hypothesis can be <em>any</em> logical proposition involving a statistic of the population (well, an estimate of the statistic usually).</p>
<p>Now we can draw a sample and calculate the same statistic but for the sample.  The goal is to try to <em>disprove</em> the currently held hypothesis. For mean, it is a matter of showing that the sample statistic is unlikely. How unlikely? It has a less than $x%$ probability of occuring. In literature, $x$ is set to $5$ for some historical reasons. So if it is so unlikel, our current hypothesis regarding the population statistic (in this case the mean) is likely wrong</p>
<p>But what if the sample mean does <em>not</em> fall in the tail region of the standard normal distribution?  Then we have failed to draw new conclusions.</p>
<p>Zed Statistics first example is set up in such a way so we can understand what we mean here. A company manager determines that it is only cost effective if the mean monthly account is greater than $70$. A sample of $200$ customers was done and the sample mean was $74$. Is this enough evidence to determine that the system is cost effective with a $5%$ confidence interval?</p>
<p>There are two ways to approach this</p>
<ul>
<li>
<p>Assume that the mean account is $\le 70$ and (try to) show the sample mean of $74$ is an outlier under that assumption. Then by contradiction, we would have shown that the mean account is $\gt 70$ (with good confidence).</p>
</li>
<li>
<p>Assume that the mean account is $\gt 70$ and the sample mean is not an outlier. Then we fail to contradict the assumption, but also don&rsquo;t gain any insights. We have to get more samples to reach a better conclusion. (TODO: clarify please)</p>
</li>
</ul>
<p>Hypothesis testing helps in reaching a conclusion from a single sample. We have to frame our hypthesis in a way so that we have a chance of rejecting the null hypothesis. The first approach at least gives us an opportunity, even though we haven&rsquo;t pushed in the numbers yet, but we can see that if the result agrees (since we might fail to reject if $74$ is not an outlier), we are able to outright determine that the mean is greater than 70 with good confidence).</p>
<p>The second approach, in the confines of hypothesis testing rules, does not enable us to draw any significant conclusion. So we would have to resort to taking more samples and all.</p>
<p>Another example. Suppose that your manager has come up with the claim based on surveys that there at least 75% of their customers like their services. A sample of 460 customers was surveyed once more and it was found that 70% of the customers like the service. Is it possible to reject the manager&rsquo;s claim with a 1% level of confidence?</p>
<p>Here we know that the underlying probability distribution is a binomial one.  The population proportion estimate $p = 75$ can be used to calculate the mean estimate $\mu = np = 460 * 75$ and std deviation estimate = $\sigma = \sqrt{np(1-p)}$</p>
<p>Now, we want to be able to reject the manager&rsquo;s claim that $p \geq 75$. So that goes directly as the null hypothesis.</p>
<p>$$
H_0: p \geq 75
$$
$$
H_1: p \lt 75
$$</p>
<p>Proving that the sample proportion is an outlier if $p = 75$ will imply that it is an outlier for any $p \geq 75$, because the sample propertion $70$ is already lower than estimated proportion $75$. Also, using tail confidence intervals is not appropriate for this situation for the same reason. Consider this - if the sample proportion was something like $80$ then $H_0$ might very well be correct, since the null claim is about $p \geq 75$ not $p = 75$. With that sorted we can write out the normalization formula</p>
<p>$$
Z = \frac{\hat{p} - p}{\sqrt{p(1-p)/n}}
$$</p>
<h2 id="conv-network-concepts">Conv Network concepts</h2>
<p>3D Image (w, h, ch). Multiple discrete convolution filters in first &ldquo;layer&rdquo;.  Each filter represents a node. Output of one node is a 2D image consisting of the filtered image. By the way, from the <a href="https://cs231n.github.io/convolutional-networks/">discussion</a> it seems the filtering is done <em>across</em> the channels, so different channels are mixed by the convolution weights.</p>
<p>So I will just introduce my own terms to make understanding a bit easier. There is just a single conv layer. The input to this layer is the image.</p>
<p>The conv layer consist of one or more filter layers. Each filter layer gets as input the image and act on it independently. A filter layer consists of the convolution weights. How these weights are mapped to individual pixels depend on wheter parameter sharing is used. If parameter sharing is used, we can just keep $n \times n$ filter matrix and slide it, the exact same thing as image convolution. However, the filter matrix is actually a tensor of shape $n \times n \times c$ where $c$ is the number of channels. It&rsquo;s still 2D convolution but the sum is done over all channels. A single filter layer produces a matrix (2D tensor) representing the convolved image (again, we can&rsquo;t quite call it &ldquo;convolved&rdquo; if we don&rsquo;t actually use convolution-based filter layer but rather a dense layer). The shape of this matrix depends on whether padding is used. If padding is used, then the shape is same as the input image (except the number of &ldquo;channels&rdquo; is $1$, therefore it is a matrix), otherwise, the convolution will decrease the size of the image by at least $2$ along the width and height.  Usually, convolution will have a stride of $1$, but this is neural nets, so we can have configurable stride. The more the stride, the lesser the size of the output matrix. Stride $S$ and depth $D$ (which represents the number of filter layers used) are hyper-params.</p>
<p>Lets say that the size of input image (ignoring the channel dimnesion) is the 2-tuple $\vec{W}$ and the zero pad is the 2-tuple $\vec{P}$ and the filter size of all conv layer nodes is $\vec{F}$ and filter stride is $\vec{S}$. Then the number of times a single node will slide along the image width and height and therefore the number of scalar outputs for this node will be</p>
<p>$$
(\vec{W} - \vec{F} + 2P)/\vec{S} + \vec{1}
$$</p>
<p><em>Intuitive explanation of the expression</em> - Of course this expression needs values that make it a positive integer tuple so there&rsquo;s a constraint on the variables. Restricting to 1D inputs and therefore 1D filters we can convince ourselves the formula is correct. You know that if stride is just $1$ then the number of consecutive $F$-tuples (i.e.  the number of times you can slide the filter over the array) is $N = W - F + 1$. We can only take every $S$-th tuple.  So there&rsquo;s $\frac{(W - F)}{S}$ tuples we can pick.
I am not gonna think about why I didn&rsquo;t take into account the  $+ 1$ in this case for now.</p>
<p>Take a moment to understand what we are doing. We are sliding a <em>single</em> node (the filter matrix) over the input pixels and that outputs a matrix itself. But that is not quite what a usual &ldquo;dense&rdquo; NN structure does. A node takes in a vector (multiple inputs) and outputs a scalar. We <em>can</em> however look at the convolve operation as multiple neurons acting on different pixels of the image instead of a single node sliding. Most of these neurons will have the same weights in this formulation.</p>
<p>These two approaches are equivalent, except since the filter matrix is the same for all these nodes, we can just keep a single node and in true image processing parlance, just slide it and therefore convolving the input pixels, hence the name convolutional network. Strangely, this so-called &ldquo;parameter sharing&rdquo; is considered as an optimization instead of the the norm. I guess it&rsquo;s because it&rsquo;s different from the regular NN approach.</p>
<h2 id="cross-entropy-loss">Cross Entropy Loss</h2>
<p><a href="https://stackoverflow.com/a/39499486/2896387">This SO answer goes into quite a bit of detail on cross entropy loss implementation in TF</a>. To describe a bit more concisely, the shape of the output matrix of logits is $(\text{BatchSize}, \text{NumLabels})$. First we want to take the log of each output value of softmax so <code>Y * tf.log(y)</code> does that (the shape of <code>Y</code> and <code>y</code> are same - one is train output, the other is predicted output. $Y$ can also be seen as a probability distribution just like $y$, except kind of simpler, it has probability $1$ at a single label. The cross entropy loss according to the formula in wikipedia gives the loss at row $j$</p>
<p>$$
L_j = -\sum_{j=1}^\text{NumLabels} Y_j \log(y_j)
$$</p>
<p>The equivalent code would be <code>losses = tf.reduce_sum(Y * tf.log(y), axis=1)</code></p>
<p>However, we want to sum over the losses over the rows also, since we want to calculate the total loss for the batch. Then we can just avoid specifying the $axis$ argument.</p>
<h2 id="transparent-logs-paper">Transparent logs paper</h2>
<p>H = cryptographic (i.e. one-way) hash function</p>
<p>H(M) = fixed size output</p>
<p>When N = number of records is not a power of 2, we can break N into sum of power
of 2s (just like binary to decimal conversion).</p>
<p>Then build Merkle trees for each of these counts, and connect them. That is, the
root nodes of each of the individual power-of-2-size binary trees become child
eode of the new binary tree.</p>

		</section>

		<div class="post-tags">
			
			
			
		</div>
	</article>
</main>
<footer>
<hr>⚡️
	2021  <a href="https://github.com/athul/archie">Archie Theme</a> | Built with <a href="https://gohugo.io">Hugo</a>
</footer>




</div>
    </body>
</html>
